{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c168673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: np.float64(0.6133333333333333), 1: np.float64(2.7058823529411766)}\n",
      "✅ Loaded best Sequential hyperparameters: {'Model No.': 5, 'Layers': '[16, 8]', 'Learning Rate': 0.001, 'Dropout': 0.0, 'Accuracy': 0.7333333333333333, 'Precision': 0.3809523809523809, 'Recall': 0.7272727272727273, 'F1-Score': 0.5, 'ROC-AUC': 0.7847866419294991}\n",
      "✅ Loaded best Wide & Deep hyperparameters: {'Model No.': 3, 'Layers': '[10]', 'Learning Rate': 0.01, 'Dropout': 0.0, 'Accuracy': 0.7666666666666667, 'Precision': 0.3846153846153846, 'Recall': 0.4545454545454545, 'F1-Score': 0.4166666666666667, 'ROC-AUC': 0.7105751391465678}\n",
      "\n",
      "Training Final Sequential Model...\n",
      "Epoch 1/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6495 - auc: 0.3732 - loss: 0.7560 - val_accuracy: 0.5424 - val_auc: 0.4044 - val_loss: 0.6629\n",
      "Epoch 2/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5693 - auc: 0.4039 - loss: 0.6872 - val_accuracy: 0.5085 - val_auc: 0.4081 - val_loss: 0.6724\n",
      "Epoch 3/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5231 - auc: 0.4354 - loss: 0.7524 - val_accuracy: 0.5085 - val_auc: 0.4233 - val_loss: 0.6825\n",
      "Epoch 4/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5023 - auc: 0.4945 - loss: 0.7108 - val_accuracy: 0.4576 - val_auc: 0.4508 - val_loss: 0.6864\n",
      "Epoch 5/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5335 - auc: 0.5625 - loss: 0.6638 - val_accuracy: 0.4407 - val_auc: 0.4602 - val_loss: 0.6857\n",
      "Epoch 6/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4832 - auc: 0.5487 - loss: 0.7011 - val_accuracy: 0.4237 - val_auc: 0.4621 - val_loss: 0.6861\n",
      "Epoch 7/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4899 - auc: 0.5135 - loss: 0.7216 - val_accuracy: 0.4746 - val_auc: 0.4943 - val_loss: 0.6792\n",
      "Epoch 8/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5204 - auc: 0.6168 - loss: 0.6447 - val_accuracy: 0.5763 - val_auc: 0.5189 - val_loss: 0.6709\n",
      "Epoch 9/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5527 - auc: 0.6121 - loss: 0.6660 - val_accuracy: 0.5763 - val_auc: 0.5549 - val_loss: 0.6642\n",
      "Epoch 10/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5463 - auc: 0.6469 - loss: 0.6646 - val_accuracy: 0.5763 - val_auc: 0.5748 - val_loss: 0.6591\n",
      "Epoch 11/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5780 - auc: 0.6661 - loss: 0.6552 - val_accuracy: 0.5763 - val_auc: 0.5871 - val_loss: 0.6549\n",
      "Epoch 12/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5888 - auc: 0.7045 - loss: 0.6401 - val_accuracy: 0.5763 - val_auc: 0.6023 - val_loss: 0.6501\n",
      "Epoch 13/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6064 - auc: 0.7108 - loss: 0.6166 - val_accuracy: 0.6102 - val_auc: 0.6326 - val_loss: 0.6392\n",
      "Epoch 14/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5977 - auc: 0.7175 - loss: 0.6441 - val_accuracy: 0.6271 - val_auc: 0.6411 - val_loss: 0.6360\n",
      "Epoch 15/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5948 - auc: 0.7088 - loss: 0.6214 - val_accuracy: 0.6441 - val_auc: 0.6619 - val_loss: 0.6249\n",
      "Epoch 16/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6406 - auc: 0.7693 - loss: 0.6039 - val_accuracy: 0.6441 - val_auc: 0.6648 - val_loss: 0.6164\n",
      "Epoch 17/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6448 - auc: 0.7545 - loss: 0.6504 - val_accuracy: 0.6441 - val_auc: 0.6837 - val_loss: 0.6097\n",
      "Epoch 18/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6578 - auc: 0.7652 - loss: 0.5897 - val_accuracy: 0.6780 - val_auc: 0.6913 - val_loss: 0.6020\n",
      "Epoch 19/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6562 - auc: 0.7686 - loss: 0.6095 - val_accuracy: 0.6780 - val_auc: 0.6970 - val_loss: 0.5977\n",
      "Epoch 20/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6473 - auc: 0.7841 - loss: 0.6390 - val_accuracy: 0.6780 - val_auc: 0.7017 - val_loss: 0.5872\n",
      "Epoch 21/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6807 - auc: 0.8062 - loss: 0.5821 - val_accuracy: 0.6780 - val_auc: 0.7112 - val_loss: 0.5769\n",
      "Epoch 22/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6248 - auc: 0.7573 - loss: 0.5885 - val_accuracy: 0.6949 - val_auc: 0.7140 - val_loss: 0.5730\n",
      "Epoch 23/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6692 - auc: 0.7798 - loss: 0.6023 - val_accuracy: 0.6949 - val_auc: 0.7206 - val_loss: 0.5689\n",
      "Epoch 24/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6871 - auc: 0.8180 - loss: 0.5743 - val_accuracy: 0.7119 - val_auc: 0.7292 - val_loss: 0.5602\n",
      "Epoch 25/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7040 - auc: 0.8306 - loss: 0.5717 - val_accuracy: 0.7119 - val_auc: 0.7311 - val_loss: 0.5533\n",
      "Epoch 26/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7077 - auc: 0.8095 - loss: 0.5310 - val_accuracy: 0.7119 - val_auc: 0.7405 - val_loss: 0.5472\n",
      "Epoch 27/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6962 - auc: 0.7933 - loss: 0.5233 - val_accuracy: 0.7119 - val_auc: 0.7348 - val_loss: 0.5490\n",
      "Epoch 28/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7028 - auc: 0.8140 - loss: 0.5474 - val_accuracy: 0.7119 - val_auc: 0.7358 - val_loss: 0.5415\n",
      "Epoch 29/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7190 - auc: 0.8091 - loss: 0.5188 - val_accuracy: 0.7119 - val_auc: 0.7396 - val_loss: 0.5401\n",
      "Epoch 30/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7408 - auc: 0.8473 - loss: 0.5019 - val_accuracy: 0.7119 - val_auc: 0.7443 - val_loss: 0.5344\n",
      "Epoch 31/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7397 - auc: 0.8503 - loss: 0.5210 - val_accuracy: 0.7119 - val_auc: 0.7443 - val_loss: 0.5380\n",
      "Epoch 32/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7129 - auc: 0.8351 - loss: 0.5163 - val_accuracy: 0.7119 - val_auc: 0.7443 - val_loss: 0.5374\n",
      "Epoch 33/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7463 - auc: 0.8593 - loss: 0.5339 - val_accuracy: 0.7119 - val_auc: 0.7491 - val_loss: 0.5342\n",
      "Epoch 34/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7761 - auc: 0.8726 - loss: 0.5292 - val_accuracy: 0.6949 - val_auc: 0.7585 - val_loss: 0.5228\n",
      "Epoch 35/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7441 - auc: 0.8626 - loss: 0.5047 - val_accuracy: 0.6949 - val_auc: 0.7623 - val_loss: 0.5141\n",
      "Epoch 36/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7969 - auc: 0.9033 - loss: 0.4270 - val_accuracy: 0.7119 - val_auc: 0.7718 - val_loss: 0.5031\n",
      "Epoch 37/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8027 - auc: 0.9177 - loss: 0.4296 - val_accuracy: 0.7119 - val_auc: 0.7661 - val_loss: 0.5144\n",
      "Epoch 38/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7858 - auc: 0.8960 - loss: 0.4600 - val_accuracy: 0.7119 - val_auc: 0.7689 - val_loss: 0.5133\n",
      "Epoch 39/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7858 - auc: 0.8847 - loss: 0.4586 - val_accuracy: 0.7119 - val_auc: 0.7746 - val_loss: 0.5064\n",
      "Epoch 40/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7715 - auc: 0.8832 - loss: 0.4520 - val_accuracy: 0.7119 - val_auc: 0.7737 - val_loss: 0.4992\n",
      "Epoch 41/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8014 - auc: 0.8899 - loss: 0.4499 - val_accuracy: 0.7119 - val_auc: 0.7718 - val_loss: 0.5013\n",
      "Epoch 42/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8151 - auc: 0.9101 - loss: 0.4121 - val_accuracy: 0.7119 - val_auc: 0.7746 - val_loss: 0.4948\n",
      "Epoch 43/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8131 - auc: 0.9142 - loss: 0.4549 - val_accuracy: 0.7119 - val_auc: 0.7689 - val_loss: 0.5022\n",
      "Epoch 44/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8163 - auc: 0.9248 - loss: 0.4219 - val_accuracy: 0.7288 - val_auc: 0.7652 - val_loss: 0.4936\n",
      "Epoch 45/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8338 - auc: 0.9224 - loss: 0.4135 - val_accuracy: 0.7288 - val_auc: 0.7661 - val_loss: 0.4918\n",
      "Epoch 46/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8273 - auc: 0.9202 - loss: 0.3847 - val_accuracy: 0.7288 - val_auc: 0.7576 - val_loss: 0.4983\n",
      "Epoch 47/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8321 - auc: 0.9384 - loss: 0.3669 - val_accuracy: 0.7288 - val_auc: 0.7585 - val_loss: 0.4938\n",
      "Epoch 48/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8179 - auc: 0.9129 - loss: 0.3923 - val_accuracy: 0.7288 - val_auc: 0.7509 - val_loss: 0.5013\n",
      "Epoch 49/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8562 - auc: 0.9385 - loss: 0.3423 - val_accuracy: 0.7119 - val_auc: 0.7491 - val_loss: 0.4992\n",
      "Epoch 50/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8219 - auc: 0.9301 - loss: 0.4250 - val_accuracy: 0.7119 - val_auc: 0.7443 - val_loss: 0.5155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sequential model saved to models/sequential_model.h5\n",
      "\n",
      "Training Final Wide & Deep Model...\n",
      "Epoch 1/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.2713 - auc: 0.4630 - loss: 0.8620 - val_accuracy: 0.5593 - val_auc: 0.6534 - val_loss: 0.7142\n",
      "Epoch 2/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5384 - auc: 0.5082 - loss: 0.7287 - val_accuracy: 0.6441 - val_auc: 0.7614 - val_loss: 0.5939\n",
      "Epoch 3/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6660 - auc: 0.6710 - loss: 0.6404 - val_accuracy: 0.6610 - val_auc: 0.7756 - val_loss: 0.6202\n",
      "Epoch 4/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6337 - auc: 0.7319 - loss: 0.6531 - val_accuracy: 0.6102 - val_auc: 0.7822 - val_loss: 0.6925\n",
      "Epoch 5/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5262 - auc: 0.7200 - loss: 0.6314 - val_accuracy: 0.6610 - val_auc: 0.7898 - val_loss: 0.5909\n",
      "Epoch 6/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6844 - auc: 0.7465 - loss: 0.5880 - val_accuracy: 0.7288 - val_auc: 0.7907 - val_loss: 0.5457\n",
      "Epoch 7/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7276 - auc: 0.7936 - loss: 0.6069 - val_accuracy: 0.6441 - val_auc: 0.7727 - val_loss: 0.6139\n",
      "Epoch 8/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7224 - auc: 0.8355 - loss: 0.5370 - val_accuracy: 0.6949 - val_auc: 0.7699 - val_loss: 0.5819\n",
      "Epoch 9/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7528 - auc: 0.8433 - loss: 0.4918 - val_accuracy: 0.7119 - val_auc: 0.7708 - val_loss: 0.5470\n",
      "Epoch 10/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7572 - auc: 0.8247 - loss: 0.5358 - val_accuracy: 0.6780 - val_auc: 0.7604 - val_loss: 0.6267\n",
      "Epoch 11/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7662 - auc: 0.8776 - loss: 0.4482 - val_accuracy: 0.6949 - val_auc: 0.7642 - val_loss: 0.5884\n",
      "Epoch 12/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7626 - auc: 0.8538 - loss: 0.4938 - val_accuracy: 0.7119 - val_auc: 0.7633 - val_loss: 0.5850\n",
      "Epoch 13/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7914 - auc: 0.8899 - loss: 0.4685 - val_accuracy: 0.6780 - val_auc: 0.7699 - val_loss: 0.6148\n",
      "Epoch 14/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7480 - auc: 0.8433 - loss: 0.5063 - val_accuracy: 0.6949 - val_auc: 0.7614 - val_loss: 0.6113\n",
      "Epoch 15/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8215 - auc: 0.8984 - loss: 0.4284 - val_accuracy: 0.7119 - val_auc: 0.7595 - val_loss: 0.5816\n",
      "Epoch 16/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8122 - auc: 0.8885 - loss: 0.4503 - val_accuracy: 0.6949 - val_auc: 0.7576 - val_loss: 0.6141\n",
      "Epoch 17/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8259 - auc: 0.8801 - loss: 0.4651 - val_accuracy: 0.6949 - val_auc: 0.7491 - val_loss: 0.6273\n",
      "Epoch 18/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8043 - auc: 0.9093 - loss: 0.4345 - val_accuracy: 0.7119 - val_auc: 0.7472 - val_loss: 0.6222\n",
      "Epoch 19/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8437 - auc: 0.9107 - loss: 0.4136 - val_accuracy: 0.7119 - val_auc: 0.7358 - val_loss: 0.6205\n",
      "Epoch 20/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8445 - auc: 0.9264 - loss: 0.3865 - val_accuracy: 0.7288 - val_auc: 0.7367 - val_loss: 0.6352\n",
      "Epoch 21/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8425 - auc: 0.9244 - loss: 0.3953 - val_accuracy: 0.7119 - val_auc: 0.7358 - val_loss: 0.6561\n",
      "Epoch 22/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8365 - auc: 0.9152 - loss: 0.3836 - val_accuracy: 0.6949 - val_auc: 0.7254 - val_loss: 0.6407\n",
      "Epoch 23/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8136 - auc: 0.8886 - loss: 0.4372 - val_accuracy: 0.6949 - val_auc: 0.7188 - val_loss: 0.6425\n",
      "Epoch 24/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8283 - auc: 0.9047 - loss: 0.3967 - val_accuracy: 0.6949 - val_auc: 0.7121 - val_loss: 0.6489\n",
      "Epoch 25/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8394 - auc: 0.9280 - loss: 0.3755 - val_accuracy: 0.6780 - val_auc: 0.7131 - val_loss: 0.7043\n",
      "Epoch 26/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8486 - auc: 0.9298 - loss: 0.3526 - val_accuracy: 0.6949 - val_auc: 0.7102 - val_loss: 0.6623\n",
      "Epoch 27/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8304 - auc: 0.9098 - loss: 0.4068 - val_accuracy: 0.6780 - val_auc: 0.6903 - val_loss: 0.7060\n",
      "Epoch 28/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8594 - auc: 0.9380 - loss: 0.3466 - val_accuracy: 0.6780 - val_auc: 0.6922 - val_loss: 0.6980\n",
      "Epoch 29/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8497 - auc: 0.9267 - loss: 0.3544 - val_accuracy: 0.6780 - val_auc: 0.7036 - val_loss: 0.7039\n",
      "Epoch 30/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8246 - auc: 0.9240 - loss: 0.3606 - val_accuracy: 0.6610 - val_auc: 0.7017 - val_loss: 0.7040\n",
      "Epoch 31/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8760 - auc: 0.9367 - loss: 0.3307 - val_accuracy: 0.6610 - val_auc: 0.6913 - val_loss: 0.7453\n",
      "Epoch 32/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8602 - auc: 0.9304 - loss: 0.3320 - val_accuracy: 0.6780 - val_auc: 0.6856 - val_loss: 0.7011\n",
      "Epoch 33/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8465 - auc: 0.9343 - loss: 0.3453 - val_accuracy: 0.6949 - val_auc: 0.6979 - val_loss: 0.7078\n",
      "Epoch 34/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8829 - auc: 0.9561 - loss: 0.2881 - val_accuracy: 0.6610 - val_auc: 0.6780 - val_loss: 0.7221\n",
      "Epoch 35/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8869 - auc: 0.9556 - loss: 0.2985 - val_accuracy: 0.6610 - val_auc: 0.6733 - val_loss: 0.7515\n",
      "Epoch 36/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8660 - auc: 0.9389 - loss: 0.3289 - val_accuracy: 0.7119 - val_auc: 0.6894 - val_loss: 0.7478\n",
      "Epoch 37/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8793 - auc: 0.9397 - loss: 0.3110 - val_accuracy: 0.6949 - val_auc: 0.6828 - val_loss: 0.7319\n",
      "Epoch 38/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8686 - auc: 0.9433 - loss: 0.3223 - val_accuracy: 0.6610 - val_auc: 0.6780 - val_loss: 0.7320\n",
      "Epoch 39/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8434 - auc: 0.9374 - loss: 0.3313 - val_accuracy: 0.6780 - val_auc: 0.6828 - val_loss: 0.7719\n",
      "Epoch 40/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8662 - auc: 0.9571 - loss: 0.2853 - val_accuracy: 0.6610 - val_auc: 0.6714 - val_loss: 0.7565\n",
      "Epoch 41/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8611 - auc: 0.9421 - loss: 0.3038 - val_accuracy: 0.7119 - val_auc: 0.6856 - val_loss: 0.7512\n",
      "Epoch 42/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8801 - auc: 0.9498 - loss: 0.2976 - val_accuracy: 0.7119 - val_auc: 0.6951 - val_loss: 0.7721\n",
      "Epoch 43/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8820 - auc: 0.9545 - loss: 0.2955 - val_accuracy: 0.6780 - val_auc: 0.6913 - val_loss: 0.7701\n",
      "Epoch 44/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8927 - auc: 0.9643 - loss: 0.2703 - val_accuracy: 0.6780 - val_auc: 0.6809 - val_loss: 0.7639\n",
      "Epoch 45/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8877 - auc: 0.9620 - loss: 0.2799 - val_accuracy: 0.6780 - val_auc: 0.6771 - val_loss: 0.7702\n",
      "Epoch 46/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8931 - auc: 0.9641 - loss: 0.2817 - val_accuracy: 0.6949 - val_auc: 0.6932 - val_loss: 0.7864\n",
      "Epoch 47/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8955 - auc: 0.9622 - loss: 0.2638 - val_accuracy: 0.6949 - val_auc: 0.6884 - val_loss: 0.7689\n",
      "Epoch 48/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9140 - auc: 0.9698 - loss: 0.2545 - val_accuracy: 0.6780 - val_auc: 0.6866 - val_loss: 0.7582\n",
      "Epoch 49/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8812 - auc: 0.9585 - loss: 0.2741 - val_accuracy: 0.7119 - val_auc: 0.6866 - val_loss: 0.7752\n",
      "Epoch 50/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9059 - auc: 0.9709 - loss: 0.2417 - val_accuracy: 0.6949 - val_auc: 0.6837 - val_loss: 0.7943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wide & Deep model saved to models/wide_deep_model.h5\n"
     ]
    }
   ],
   "source": [
    "# 04-train-deep-learning-models.ipynb\n",
    "\n",
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create directories if not present\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# 2. Load preprocessed datasets\n",
    "train = pd.read_csv(\"processed_data/train.csv\")\n",
    "val = pd.read_csv(\"processed_data/val.csv\")\n",
    "test = pd.read_csv(\"processed_data/test.csv\")\n",
    "\n",
    "X_train = train.drop(\"G3_binary\", axis=1)\n",
    "y_train = train[\"G3_binary\"]\n",
    "X_val = val.drop(\"G3_binary\", axis=1)\n",
    "y_val = val[\"G3_binary\"]\n",
    "X_test = test.drop(\"G3_binary\", axis=1)\n",
    "y_test = test[\"G3_binary\"]\n",
    "\n",
    "# 3. Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=np.unique(y_train),\n",
    "                                     y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(\"Class weights:\", class_weights_dict)\n",
    "\n",
    "# 4. Load best hyperparameters from tuning results\n",
    "seq_params = pd.read_csv(\"results/sequential_hyperparameter_results.csv\").sort_values(\n",
    "    by=[\"F1-Score\", \"ROC-AUC\"], ascending=False).iloc[0]\n",
    "\n",
    "wide_deep_params = pd.read_csv(\"results/widendeep_hyperparameter_results.csv\").sort_values(\n",
    "    by=[\"F1-Score\", \"ROC-AUC\"], ascending=False).iloc[0]\n",
    "\n",
    "print(\"✅ Loaded best Sequential hyperparameters:\", seq_params.to_dict())\n",
    "print(\"✅ Loaded best Wide & Deep hyperparameters:\", wide_deep_params.to_dict())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Train Final Sequential Model\n",
    "# ---------------------------------------------------\n",
    "print(\"\\nTraining Final Sequential Model...\")\n",
    "\n",
    "seq_model = keras.Sequential()\n",
    "seq_model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "for units in eval(seq_params[\"Layers\"]):\n",
    "    seq_model.add(layers.Dense(int(units), activation='relu'))\n",
    "    if float(seq_params[\"Dropout\"]) > 0:\n",
    "        seq_model.add(layers.Dropout(float(seq_params[\"Dropout\"])))\n",
    "seq_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=float(seq_params[\"Learning Rate\"]))\n",
    "seq_model.compile(optimizer=optimizer,\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\")])\n",
    "\n",
    "seq_model.fit(X_train, y_train,\n",
    "              validation_data=(X_val, y_val),\n",
    "              epochs=50,\n",
    "              batch_size=32,\n",
    "              class_weight=class_weights_dict,\n",
    "              verbose=1)\n",
    "\n",
    "seq_model.save(\"models/sequential_model.h5\")\n",
    "print(\"✅ Sequential model saved to models/sequential_model.h5\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6. Train Final Wide & Deep Model\n",
    "# ---------------------------------------------------\n",
    "print(\"\\nTraining Final Wide & Deep Model...\")\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "cat_cols = [col for col in X_train.columns if any(prefix in col for prefix in \n",
    "    ['school_', 'sex_', 'address_', 'famsize_', 'Pstatus_', 'Mjob_', 'Fjob_', \n",
    "     'reason_', 'guardian_', 'schoolsup_', 'famsup_', 'paid_', 'activities_', \n",
    "     'nursery_', 'higher_', 'internet_', 'romantic_'])]\n",
    "num_cols = [col for col in X_train.columns if col not in cat_cols]\n",
    "\n",
    "X_train_wide, X_val_wide, X_test_wide = X_train[cat_cols], X_val[cat_cols], X_test[cat_cols]\n",
    "X_train_deep, X_val_deep, X_test_deep = X_train[num_cols], X_val[num_cols], X_test[num_cols]\n",
    "\n",
    "# Build Wide & Deep\n",
    "input_wide = layers.Input(shape=(X_train_wide.shape[1],), name=\"wide_input\")\n",
    "input_deep = layers.Input(shape=(X_train_deep.shape[1],), name=\"deep_input\")\n",
    "\n",
    "deep = input_deep\n",
    "for units in eval(str(wide_deep_params[\"Layers\"])):\n",
    "    deep = layers.Dense(int(units), activation='relu')(deep)\n",
    "    if float(wide_deep_params[\"Dropout\"]) > 0:\n",
    "        deep = layers.Dropout(float(wide_deep_params[\"Dropout\"]))(deep)\n",
    "\n",
    "combined = layers.concatenate([input_wide, deep])\n",
    "output = layers.Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "wide_deep_model = keras.Model(inputs=[input_wide, input_deep], outputs=output)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=float(wide_deep_params[\"Learning Rate\"]))\n",
    "wide_deep_model.compile(optimizer=optimizer,\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=['accuracy', keras.metrics.AUC(name='auc')])\n",
    "\n",
    "wide_deep_model.fit([X_train_wide, X_train_deep], y_train,\n",
    "                    validation_data=([X_val_wide, X_val_deep], y_val),\n",
    "                    epochs=50, batch_size=32,\n",
    "                    class_weight=class_weights_dict,\n",
    "                    verbose=1)\n",
    "\n",
    "wide_deep_model.save(\"models/wide_deep_model.h5\")\n",
    "print(\"✅ Wide & Deep model saved to models/wide_deep_model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
